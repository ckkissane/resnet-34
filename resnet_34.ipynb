{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet_34.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOoFoLgJg0o+Y5m9RgP7riE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ckkissane/resnet-34/blob/main/resnet_34.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wC2LdvFEJNhI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.nn import Module, Parameter\n",
        "import math\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement building blocks"
      ],
      "metadata": {
        "id": "aGhtaPqWVqSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# implement Conv2d\n",
        "def force_pair(v):\n",
        "    return v if isinstance(v, tuple) else (v, v)\n",
        "\n",
        "def conv2d(x, weights, stride=1, padding=0):\n",
        "    sH, sW = force_pair(stride)\n",
        "    pH, pW = force_pair(padding)\n",
        "    B, iC, iH, iW = x.shape\n",
        "    oC, _, kH, kW = weights.shape\n",
        "    oH = (iH + 2*pH - kH) // sH + 1\n",
        "    oW = (iW + 2*pW - kW) // sW + 1\n",
        "\n",
        "    padded_x = torch.nn.functional.pad(x, [pW, pW, pH, pH])\n",
        "\n",
        "    conv_size = (B, iC, oH, oW, kH, kW)\n",
        "    bs, cs, hs, ws = padded_x.stride()\n",
        "    conv_stride = (bs, cs, hs*sH, ws*sW, hs, ws)\n",
        "    strided_x = torch.as_strided(padded_x, size=conv_size, stride=conv_stride)\n",
        "\n",
        "    return torch.einsum('bcxyij,ocij->boxy', strided_x, weights)\n",
        "\n",
        "class Conv2d(Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
        "        super().__init__()\n",
        "        kernel_size = force_pair(kernel_size)\n",
        "        self.stride = force_pair(stride)\n",
        "        self.padding = force_pair(padding)\n",
        "\n",
        "        weight_size = (out_channels, in_channels, *kernel_size)\n",
        "        fan_in = np.prod(weight_size[1:])\n",
        "        self.weight = Parameter(torch.randn(weight_size) * math.sqrt(2 / fan_in))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return conv2d(\n",
        "            x,\n",
        "            self.weight,\n",
        "            stride=self.stride,\n",
        "            padding=self.padding\n",
        "        )"
      ],
      "metadata": {
        "id": "olnkDO1F5cTm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# implement BatchNorm2d\n",
        "class BatchNorm2d(Module):\n",
        "    def __init__(self, num_features, eps=1e-5, momentum=0.1):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.momentum = momentum\n",
        "        self.weight = Parameter(torch.ones(num_features))\n",
        "        self.bias = Parameter(torch.zeros(num_features))\n",
        "        self.register_buffer('running_mean', torch.zeros(num_features))\n",
        "        self.register_buffer('running_var', torch.ones(num_features))\n",
        "        self.register_buffer('num_batches_tracked', torch.tensor(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        ids = (0, 2, 3)\n",
        "        if self.training:\n",
        "            mean = x.mean(ids)\n",
        "            var = x.var(ids, unbiased=False)\n",
        "            a = self.momentum\n",
        "            self.running_mean.data = (1 - a) * self.running_mean.data + a * mean\n",
        "            self.running_var.data = (1 - a) * self.running_var.data + a * var\n",
        "            self.num_batches_tracked.data += 1\n",
        "        else:\n",
        "            mean = self.running_mean\n",
        "            var = self.running_var\n",
        "\n",
        "        rs = lambda u : u.reshape(1, -1, 1, 1)\n",
        "        return rs(self.weight) * (x - rs(mean)) / torch.sqrt(rs(var) + self.eps) + rs(self.bias)"
      ],
      "metadata": {
        "id": "6yhDRnOs96jO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# implement ReLU\n",
        "def relu(tensor):\n",
        "    tensor[tensor < 0] = 0\n",
        "    return tensor\n",
        "\n",
        "class ReLU(Module):\n",
        "    def forward(self, x):\n",
        "        return relu(x)"
      ],
      "metadata": {
        "id": "DUmIem120pPm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# implement MaxPool2d\n",
        "def maxpool2d(x, kernel_size, stride=None, padding=0):\n",
        "    if stride is None:\n",
        "        stride = kernel_size\n",
        "    B, iC, iH, iW = x.shape\n",
        "    kH, kW = force_pair(kernel_size)\n",
        "    sH, sW = force_pair(stride)\n",
        "    pH, pW = force_pair(padding)\n",
        "    oH = (iH + 2*pH - kH) // sH + 1\n",
        "    oW = (iW + 2*pW - kW) // sW + 1\n",
        "\n",
        "    padded_x = torch.functional.F.pad(x, [pW, pW, pH, pH], value=-float('inf'))\n",
        "\n",
        "    conv_size = (B, iC, oH, oW, kH, kW)\n",
        "    bs, cs, hs, ws = padded_x.stride()\n",
        "    conv_stride = (bs, cs, hs*sH, ws*sW, hs, ws)\n",
        "    strided_x = torch.as_strided(padded_x, size=conv_size, stride=conv_stride)\n",
        "\n",
        "    return strided_x.amax((-2, -1))\n",
        "\n",
        "class MaxPool2d(Module):\n",
        "    def __init__(self, kernel_size, stride=None, padding=1):\n",
        "        super().__init__()\n",
        "        if stride is None:\n",
        "            stride = kernel_size\n",
        "        self.kernel_size = force_pair(kernel_size)\n",
        "        self.stride = force_pair(stride)\n",
        "        self.padding = force_pair(padding)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return maxpool2d(\n",
        "            x,\n",
        "            self.kernel_size,\n",
        "            stride=self.stride,\n",
        "            padding=self.padding\n",
        "        )"
      ],
      "metadata": {
        "id": "GQGQjg1xFgq2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# implement AdaptiveAvgPool2d\n",
        "def avg_pool2d(x, kernel_size, stride, padding=0):\n",
        "    B, iC, iH, iW = x.shape\n",
        "    kH, kW = force_pair(kernel_size)\n",
        "    sH, sW = force_pair(stride)\n",
        "    pH, pW = force_pair(padding)\n",
        "    oH = (iH + 2*pH - kH) // sH + 1\n",
        "    oW = (iW + 2*pW - kW) // sW + 1\n",
        "\n",
        "    padded_x = torch.functional.F.pad(x, [pW, pW, pH, pH])\n",
        "\n",
        "    conv_size = (B, iC, oH, oW, kH, kW)\n",
        "    bs, cs, hs, ws = padded_x.stride()\n",
        "    conv_stride = (bs, cs, hs*sH, ws*sW, hs, ws)\n",
        "    strided_x = torch.as_strided(padded_x, size=conv_size, stride=conv_stride)\n",
        "\n",
        "    return strided_x.mean((-2, -1))\n",
        "\n",
        "def adaptive_avg_pool2d(x, output_size):\n",
        "    input_size = torch.tensor(x.size()[-2:])\n",
        "    output_size = torch.tensor(output_size)\n",
        "    stride = input_size // output_size\n",
        "    kernel_size = input_size - (output_size - 1) * stride\n",
        "    return avg_pool2d(\n",
        "        x, \n",
        "        kernel_size=tuple(kernel_size), \n",
        "        stride=tuple(stride)\n",
        "    )\n",
        "\n",
        "class AdaptiveAvgPool2d(Module):\n",
        "    def __init__(self, output_size):\n",
        "        super().__init__()\n",
        "        self.output_size = output_size\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return adaptive_avg_pool2d(x, self.output_size)"
      ],
      "metadata": {
        "id": "GVkcYQZrdCyY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# implement Flatten\n",
        "class Flatten(Module):\n",
        "    def __init__(self, start_dim=1, end_dim=-1):\n",
        "        super().__init__()\n",
        "        self.start_dim = start_dim\n",
        "        self.end_dim = end_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x.flatten(self.start_dim, self.end_dim)"
      ],
      "metadata": {
        "id": "wYNvrZkwQjGK"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# implement Linear\n",
        "class Linear(Module):\n",
        "    def __init__(self, in_features, out_features, bias=True):\n",
        "        super().__init__()\n",
        "        weight_bound = 1 / np.sqrt(in_features)\n",
        "        self.weight = Parameter(torch.FloatTensor(out_features, in_features).uniform_(-weight_bound, weight_bound))\n",
        "        if bias:\n",
        "            bias_bound = 1 / np.sqrt(in_features)\n",
        "            self.bias = Parameter(torch.FloatTensor(out_features).uniform_(-bias_bound, bias_bound)) \n",
        "        else:\n",
        "            self.bias = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.einsum('...j,kj->...k', x, self.weight)\n",
        "        if self.bias is not None:\n",
        "            x += self.bias\n",
        "        return x"
      ],
      "metadata": {
        "id": "kbnDBdB5hEgD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# implement Sequential\n",
        "class Sequential(Module):\n",
        "    def __init__(self, *args):\n",
        "        super(Sequential, self).__init__()\n",
        "        for idx, module in enumerate(args):\n",
        "            self.add_module(str(idx), module)\n",
        "    \n",
        "    def __iter__(self):\n",
        "        return iter(self._modules.values())\n",
        "    \n",
        "    def forward(self, x):\n",
        "        for module in self:\n",
        "            x = module(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "GzqTBFn6Cmhz"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement ResNet34"
      ],
      "metadata": {
        "id": "B5rG88Z3Vxrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# implement ResidualBlock\n",
        "class ResidualBlock(Module):\n",
        "    def __init__(self, in_feats, out_feats, stride=1):\n",
        "        super().__init__()\n",
        "        self.net = Sequential(\n",
        "            Conv2d(in_feats, out_feats, kernel_size=3, stride=stride, padding=1),\n",
        "            BatchNorm2d(out_feats),\n",
        "            ReLU(),\n",
        "            Conv2d(out_feats, out_feats, kernel_size=3, padding=1),\n",
        "            BatchNorm2d(out_feats),\n",
        "        )\n",
        "        self.downsample = Sequential(\n",
        "            Conv2d(in_feats, out_feats, kernel_size=1, stride=stride),\n",
        "            BatchNorm2d(out_feats)\n",
        "        ) if stride != 1 else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_out = self.net(x)\n",
        "        x_out = x if self.downsample is None else self.downsample(x)\n",
        "        out = relu(x_out + y_out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "aOvq66urYvIx"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# implement ResNet34 model\n",
        "class ResNet34(Module):\n",
        "    def __init__(self, n_outs=1000, n_blocks_per_n_feats=[3, 4, 6, 3]):\n",
        "        super().__init__()\n",
        "        in_feats0 = 64\n",
        "        self.in_layers = Sequential(\n",
        "            Conv2d(3, in_feats0, kernel_size=7, stride=2, padding=3),\n",
        "            BatchNorm2d(in_feats0),\n",
        "            ReLU(),\n",
        "            MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        )\n",
        "\n",
        "        all_out_feats = [64, 128, 256, 512]\n",
        "        all_in_feats = [in_feats0] + all_out_feats[:-1]\n",
        "        strides = [1, 2, 2, 2]\n",
        "        self.residual_layers = Sequential(\n",
        "            *(\n",
        "                Sequential(\n",
        "                    ResidualBlock(in_feats, out_feats, stride),\n",
        "                    *(ResidualBlock(out_feats, out_feats) for _ in range(num_blocks - 1))\n",
        "                ) for in_feats, out_feats, stride, num_blocks in zip(all_in_feats, all_out_feats, strides, n_blocks_per_n_feats)\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.out_layers = Sequential(\n",
        "            AdaptiveAvgPool2d((1, 1)),\n",
        "            Flatten(),\n",
        "            Linear(in_features=512, out_features=n_outs)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.in_layers(x)\n",
        "        x = self.residual_layers(x)\n",
        "        x = self.out_layers(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "h_egKvIGNsKq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "HiAFP91hV3AU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train model on CIFAR10 training data\n",
        "import torchvision\n",
        "from tqdm import tqdm\n",
        "from torch import optim\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "train_transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.PILToTensor(), \n",
        "    torchvision.transforms.ConvertImageDtype(torch.float)\n",
        "])\n",
        "\n",
        "cifar10_train = torchvision.datasets.CIFAR10(\n",
        "    root='./data', \n",
        "    train=True,\n",
        "    download=True, \n",
        "    transform=train_transforms\n",
        ")\n",
        "trainloader = torch.utils.data.DataLoader(cifar10_train, batch_size=128, shuffle=True)\n",
        "\n",
        "model = ResNet34(n_outs=10).to(device).train()\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    for i, (x, y) in enumerate(tqdm(trainloader)):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        y_hat = model(x)\n",
        "        loss = loss_fn(y_hat, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if i % 500 == 0:\n",
        "            print(f\"epoch {epoch}, loss is {loss}\")"
      ],
      "metadata": {
        "id": "35531hNDNg1x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc420a42-f5fa-48d6-bf4a-237a8584d87b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/391 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  \n",
            "  1%|          | 2/391 [00:00<01:22,  4.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0, loss is 2.7241697311401367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:00<00:00,  6.47it/s]\n",
            "  1%|          | 2/391 [00:00<01:05,  5.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1, loss is 1.1102850437164307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:00<00:00,  6.42it/s]\n",
            "  1%|          | 2/391 [00:00<01:06,  5.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2, loss is 0.7511013150215149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:01<00:00,  6.39it/s]\n",
            "  1%|          | 2/391 [00:00<01:07,  5.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3, loss is 0.5957945585250854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:01<00:00,  6.39it/s]\n",
            "  1%|          | 2/391 [00:00<01:05,  5.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4, loss is 0.5541190505027771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:01<00:00,  6.39it/s]\n",
            "  1%|          | 2/391 [00:00<01:07,  5.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5, loss is 0.504300594329834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:00<00:00,  6.44it/s]\n",
            "  1%|          | 2/391 [00:00<01:08,  5.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6, loss is 0.4518352150917053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:01<00:00,  6.40it/s]\n",
            "  1%|          | 2/391 [00:00<01:05,  5.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7, loss is 0.3907870948314667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:00<00:00,  6.45it/s]\n",
            "  1%|          | 2/391 [00:00<01:06,  5.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8, loss is 0.2827386260032654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:00<00:00,  6.46it/s]\n",
            "  1%|          | 2/391 [00:00<01:07,  5.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 9, loss is 0.2609924376010895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:01<00:00,  6.41it/s]\n",
            "  1%|          | 2/391 [00:00<01:08,  5.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10, loss is 0.208006352186203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:00<00:00,  6.45it/s]\n",
            "  1%|          | 2/391 [00:00<01:07,  5.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 11, loss is 0.11383470892906189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:01<00:00,  6.40it/s]\n",
            "  1%|          | 2/391 [00:00<01:06,  5.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 12, loss is 0.06702566146850586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:00<00:00,  6.45it/s]\n",
            "  1%|          | 2/391 [00:00<01:07,  5.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 13, loss is 0.09093046188354492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:00<00:00,  6.45it/s]\n",
            "  1%|          | 2/391 [00:00<01:05,  5.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 14, loss is 0.09256793558597565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:00<00:00,  6.41it/s]\n",
            "  1%|          | 2/391 [00:00<01:07,  5.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 15, loss is 0.11451936513185501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:00<00:00,  6.42it/s]\n",
            "  1%|          | 2/391 [00:00<01:06,  5.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 16, loss is 0.047571007162332535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:01<00:00,  6.41it/s]\n",
            "  1%|          | 2/391 [00:00<01:06,  5.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 17, loss is 0.028243839740753174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:00<00:00,  6.46it/s]\n",
            "  1%|          | 2/391 [00:00<01:05,  5.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 18, loss is 0.03648705407977104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:00<00:00,  6.48it/s]\n",
            "  1%|          | 2/391 [00:00<01:07,  5.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 19, loss is 0.045246873050928116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:01<00:00,  6.39it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference"
      ],
      "metadata": {
        "id": "RyowXO5sV5fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.PILToTensor(),\n",
        "    torchvision.transforms.ConvertImageDtype(torch.float)\n",
        "])\n",
        "                                                  \n",
        "cifar_test = torchvision.datasets.CIFAR10(\n",
        "    \"./data\",\n",
        "    transform=test_transforms,\n",
        "    download=True,\n",
        "    train=False\n",
        ")\n",
        "testloader = torch.utils.data.DataLoader(cifar_test, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        \n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print('Accuracy on 10,000 test images: ', 100*(correct/total), '%')"
      ],
      "metadata": {
        "id": "yOZlJ-IYFQHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "814d2498-1111-46cd-c7c3-3b841e0a6119"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on 10,000 test images:  74.77000000000001 %\n"
          ]
        }
      ]
    }
  ]
}